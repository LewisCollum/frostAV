#+setupfile: ../../research.org

#+title: Traffic Sign Classification
#+date: Updated: \today
#+author: Lewis Collum
*Started 02/09/2020*

* Downloading the German Traffic Sign Recognition Benchmark, GTSRB
  The following downloads the dataset, unzips it, and moves the
  internal directories around (and changes their name) to match my
  prefered directory convention.
 #+begin_src bash :async
trainSet=GTSRB_Final_Training_Images.zip
testSet=GTSRB_Final_Test_Images.zip
signNames=signnames.csv
dataDirectory="data"

function main() {
    downloadGtsrbTrainSet
    dowloadGtsrbTestSet
    downloadSignNames
    configureDataDirectory
    echo "DONE!"
}

function downloadGtsrbTrainSet() {
    if [[ ! -d "$dataDirectory/train" ]]; then
        wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/$trainSet
        unzip $trainSet -d "$dataDirectory"
        rm -f $trainSet
    fi;
}

function downloadGtsrbTrainSet() {
    if [[ ! -d "$dataDirectory/test" ]]; then
        wget https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/$testSet
        unzip $testSet -d "$dataDirectory"
        rm -f $testSet
    fi;
}

function downloadSignNames() {
    wget https://raw.githubusercontent.com/udacity/CarND-Traffic-Sign-Classifier-Project/master/"$signNames"
}

function configureDataDirectory() {
    mv "$signNames" "$dataDirectory"

    [[ -d "data/GTSRB/Final_Training/Images" ]] &&
        mv "data/GTSRB/Final_Training/Images" "data/train"

    [[ -d "data/GTSRB/Final_Test/Images" ]] &&
        mv "data/GTSRB/Final_Test/Images" "data/test"

    rm -rf "data/GTSRB"
}

main
 #+end_src

* Common Variables
  =common.py=
  #+begin_src python :tangle source/common.py
import pandas

signNames = pandas.read_csv("../data/signnames.csv")['SignName'].values

trainPath = "../data/train"
testPath = "../data/test"
modelPath = "./model"
imageSize = 32
  #+end_src

* Preprocessing
  =preprocessing.py=
  #+begin_src python :tangle source/preprocessing.py
import cv2
import numpy

clahe = cv2.createCLAHE(tileGridSize=(2,2), clipLimit=15.0)

def execute(image):
    return numpy.reshape(clahe.apply(image.astype(numpy.uint8)).astype(numpy.float64), (32, 32, 1))
  #+end_src

* Load Images using keras.preprocessing
  =batch.py=
  #+begin_src python :tangle source/batch.py :results silent
from keras.preprocessing.image import ImageDataGenerator
import numpy
import matplotlib.pyplot as pyplot
from textwrap import wrap

import common
import preprocessing

size = 32

batchGenerator = ImageDataGenerator(
    rescale = 1./255,
    preprocessing_function = preprocessing.execute,
    validation_split = 0.2)

trainIterator = batchGenerator.flow_from_directory(
    directory = common.trainPath,
    batch_size = size,
    shuffle = True,
    target_size = (common.imageSize, common.imageSize),
    color_mode = 'grayscale',
    subset = 'training')

validationIterator = batchGenerator.flow_from_directory(
    directory = common.trainPath,
    batch_size = size,
    shuffle = True,
    target_size = (common.imageSize, common.imageSize),
    color_mode = 'grayscale',
    subset = 'validation')

_images, _labels = trainIterator.next()
classCount = len(_labels[0])
sampleClasses = trainIterator.labels
sampleSize = trainIterator.n
imageShape = _images[0].shape

def classFromLabelsAt(labels, index):
    return numpy.where(labels[index] == 1)[0][0]

def signNameFromLabelsAt(labels, index):
    return common.signNames[classFromLabelsAt(labels, index)]

def plot(images, labels, titles=True, columns=5, rows=5):
    figure, axes = pyplot.subplots(rows, columns, figsize=(8,2*rows))
    figure.subplots_adjust(hspace = .6)

    for n in range(min(columns*rows, size)):
        if len(images[n, 0, 0]) == 1:
            figure.axes[n].imshow(images[n].reshape((32, 32)), cmap='gray')
        else:
            figure.axes[n].imshow(images[n])
        if titles:
            title = signNameFromLabelsAt(labels, n).title()
            wrappedTitle = "\n".join(wrap(title, 18))
            figure.axes[n].set_title(wrappedTitle, fontsize=10)

    for subplotAxes in figure.axes: subplotAxes.axis('off')
    figure.tight_layout()
  #+end_src 

* Distribution of Classes (Training Set)
  #+begin_src python :results silent :tangle source/temp.py :async
import numpy
import matplotlib.pyplot as pyplot

import common
import batch

distribution = numpy.zeros(batch.classCount)
for i in batch.sampleClasses:
    distribution[i] += 1

sortedIndices = distribution.argsort()
distribution = distribution[sortedIndices]
signNames = common.signNames[sortedIndices]

pyplot.figure(figsize=(8, 0.2*len(signNames)))
bars = pyplot.barh(signNames, distribution, align='center')
pyplot.yticks(fontsize=8)

pyplot.box(False)
pyplot.gca().get_xaxis().set_visible(False)
pyplot.gca().tick_params(length=0)

for bar in bars:
    pyplot.gca().text(
        bar.get_x() + 10,
        bar.get_y() + bar.get_height()/2,
        str(int(bar.get_width())), va='center', color='white', fontsize=7)
    
pyplot.tight_layout()

pyplot.savefig('../figure/trainingSetDistributionOfClasses.png')
  #+end_src

  [[./figure/trainingSetDistributionOfClasses.png]]

* Batch before Preprocessing
  #+begin_src python :results silent 
import matplotlib.pyplot as pyplot
import keras

import common
import batch

batchGenerator = keras.preprocessing.image.ImageDataGenerator(rescale=1./255)

trainIterator = batchGenerator.flow_from_directory(
    directory = common.trainPath,
    batch_size = batch.size,
    shuffle = True,
    target_size = (common.imageSize, common.imageSize))

images, labels = next(trainIterator)
batch.plot(images, labels)
pyplot.savefig('../figure/batchWithoutPreprocessing.png')
  #+end_src
  
  [[./figure/batchWithoutPreprocessing.png]]

* Batch with Histogram Equalization (Contrast Balancing)
  #+begin_src python :results silent :async
import batch
import matplotlib.pyplot as pyplot

images, labels = next(batch.trainIterator)
batch.plot(images, labels, columns=5, rows=2)
pyplot.savefig('../figure/batchWithPreprocessing.png')
  #+end_src

  [[./figure/batchWithPreprocessing.png]]

* Model: LeNet
  =model.py=
  #+begin_src python :tangle source/model.py
import keras
import keras.layers as layers

import common
import batch
 
model = keras.models.Sequential()
model.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=batch.imageShape))
model.add(layers.AveragePooling2D())

model.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))
model.add(layers.AveragePooling2D())

model.add(layers.Flatten())

model.add(layers.Dropout(0.2))

model.add(layers.Dense(units=1024, activation='relu'))
model.add(layers.BatchNormalization(axis=1))
model.add(layers.Dense(units=1024, activation='relu'))
model.add(layers.BatchNormalization(axis=1))
model.add(layers.Dense(units=batch.classCount, activation = 'softmax'))

if __name__ == '__main__':
    print(model.summary())
    keras.utils.plot_model(model, to_file='model.png')
  #+end_src

  #+RESULTS:
  #+begin_example
  Found 39209 images belonging to 43 classes.
  Model: "sequential_1"
  _________________________________________________________________
  Layer (type)                 Output Shape              Param #   
  =================================================================
  conv2d_1 (Conv2D)            (None, 30, 30, 6)         60        
  _________________________________________________________________
  average_pooling2d_1 (Average (None, 15, 15, 6)         0         
  _________________________________________________________________
  conv2d_2 (Conv2D)            (None, 13, 13, 16)        880       
  _________________________________________________________________
  average_pooling2d_2 (Average (None, 6, 6, 16)          0         
  _________________________________________________________________
  flatten_1 (Flatten)          (None, 576)               0         
  _________________________________________________________________
  dense_1 (Dense)              (None, 1024)              590848    
  _________________________________________________________________
  batch_normalization_1 (Batch (None, 1024)              4096      
  _________________________________________________________________
  dense_2 (Dense)              (None, 1024)              1049600   
  _________________________________________________________________
  batch_normalization_2 (Batch (None, 1024)              4096      
  _________________________________________________________________
  dense_3 (Dense)              (None, 39209)             40189225  
  =================================================================
  Total params: 41,838,805
  Trainable params: 41,834,709
  Non-trainable params: 4,096
  _________________________________________________________________
  None
  #+end_example

* Training
  =training.py=
  #+begin_src python :tangle source/training.py
from keras.optimizers import SGD
from keras.callbacks import CSVLogger

import batch
from model import model

logger = CSVLogger('training.log', separator=',', append=False)

model.compile(
    loss = 'categorical_crossentropy',
    optimizer = SGD(lr=1e-3),
    metrics = ['accuracy'])

model.fit_generator(
    batch.trainIterator,
    validation_data = batch.validationIterator,
    steps_per_epoch = batch.sampleSize/batch.size,
    epochs = 20,
    callbacks=[logger])
        
model.save('fine_tune.h5')
  #+end_src
* Accuracy & Loss for Training & Validation
  #+begin_src python :results silent :var logFile="../source/good2.log"
import pandas
import matplotlib.pyplot as pyplot

log = pandas.read_csv(logFile)

figure, axes = pyplot.subplots(1, 2, figsize=(8, 4))
axes[0].set_title('Accuracy')
axes[0].plot(log['epoch'], log['accuracy'], log['val_accuracy'])
axes[0].legend(['training accuracy', 'validation accuracy'])
axes[0].set_xlabel('epoch')

axes[1].set_title('Loss')
axes[1].plot(log['epoch'], log['loss'], log['val_loss'])
axes[1].legend(['training loss', 'validation loss'])
axes[1].set_xlabel('epoch')

figure.subplots_adjust(top=0.85)
figure.suptitle('Accuracy & Loss of Training & Validation Sets per Epoch')
pyplot.savefig("../figure/accuracyAndLoss.png")
  #+end_src

  [[./figure/accuracyAndLoss.png]]

* Testing
  #+begin_src python :tangle source/testing.py :async
import keras
from keras.models import load_model
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as pyplot
import numpy as np

import common
import preprocessing
import batch

model = load_model('fine_tune.h5')

test_generator = batch.batchGenerator.flow_from_directory(
    directory="../data", 
    target_size=(common.imageSize, common.imageSize),
    color_mode='grayscale',
    shuffle=False,
    batch_size=1,
    classes=['test'])

filenames = test_generator.filenames
nb_samples = len(filenames)

fig=pyplot.figure()
columns = 4
rows = 4

for i in range(1, columns*rows):
    x_batch, y_batch = test_generator.next()

    name = model.predict(x_batch)
    name = np.argmax(name, axis=-1)
    true_name = y_batch
    true_name = np.argmax(true_name, axis=-1)

    label_map = (batch.trainIterator.class_indices)
    label_map = dict((v,k) for k,v in label_map.items()) #flip k,v
    predictions = [label_map[k] for k in name]
    true_value = [label_map[k] for k in true_name]

    image = x_batch[0]
    fig.add_subplot(rows, columns, i)
    pyplot.axis('off')
    pyplot.title(f"guess: {predictions[0]}\nactual: {true_value[0]}")
    pyplot.imshow(image[:,:,0], cmap='gray')

pyplot.show()
  #+end_src

  #+RESULTS:
  : Found 39209 images belonging to 43 classes.
  : Found 12630 images belonging to 1 classes.

* Resources
  #+begin_export latex
  \scriptsize
  #+end_export
*** Tutorial
     - https://towardsdatascience.com/recognizing-traffic-signs-with-over-98-accuracy-using-deep-learning-86737aedc2ab
     - https://github.com/kenshiro-o/CarND-Traffic-Sign-Classifier-Project
     - https://github.com/kenshiro-o/CarND-Traffic-Sign-Classifier-Project/blob/master/Traffic_Sign_Classifier.ipynb
*** Dataset
     - https://sid.erda.dk/public/archives/daaeac0d7ce1152aea9b61d9f1e19370/published-archive.html
     - http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset
*** Loading Images
    - https://www.tensorflow.org/tutorials/load_data/images
* [0/1] Tasks                                                      :noexport:
  - [ ] Download validation/test dataset
  - [ ] Extract helper functions for plotting
